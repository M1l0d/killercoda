At the bottom of the code add the following lines to start the Prometheus server and run the model.

```
start_http_server(8080)

os.system("curl http://localhost:8080/metrics")

run_model()
run_model()
```

Based on the amount of monitor needed, you can add additional ```run_model()``` lines

Once the Prometheus server is up and running, you should be able to access the metrics on localhost. However, due to the nature of this tutorial, we will use curl to get and display the metrics in the terminal.

Now you can run the code using this command:

``` 
python3 ml_logger.py
```
